{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cb66961-2260-486c-8644-af71dbddb977",
   "metadata": {},
   "source": [
    "# Test the pipeline for an off-glacier AOI, classify snow using NDSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a28c330-f7ac-4e80-a91c-9279a34b4184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wxee is not included in the default environment. Install by uncommenting the line below.\n",
    "# !micromamba install -c conda-forge wxee -y\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "import ee\n",
    "import sys\n",
    "import wxee as wx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "\n",
    "# -----Define local folder for exports\n",
    "out_folder = '/Users/rdcrlrka/Research/glacier_snow_mapping/LemonCreek_watershed_AOI'\n",
    "\n",
    "# -----Import pipeline utilities\n",
    "# Assumes pipeline_utils.py is located one folder above this notebook\n",
    "script_path = os.getcwd()\n",
    "sys.path.append(os.path.join(script_path, '..'))\n",
    "import glasee_pipeline_utils as utils\n",
    "\n",
    "# -----Define image search settings\n",
    "# Date and month ranges (inclusive)\n",
    "date_start = '2019-04-01' \n",
    "date_end = '2019-10-31' \n",
    "month_start = 4 # April = 4\n",
    "month_end = 10 # Oct = 10\n",
    "# Minimum fill portion percentage of the AOI (0â€“100), used to remove images after mosaicking by day\n",
    "min_aoi_coverage = 70\n",
    "# Whether to mask clouds using the respective cloud mask via the geedim package\n",
    "mask_clouds = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218f6829-c347-4cce-a613-f90422f43884",
   "metadata": {},
   "source": [
    "## Authenticate GEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01ac478-36b9-49fd-865a-fecf51154f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = \"ee-raineyaberle\"\n",
    "\n",
    "try:\n",
    "    ee.Initialize(project=project_id)\n",
    "except:\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize(project=project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6bff78-286f-4515-bf6c-dfa8b4cd3211",
   "metadata": {},
   "source": [
    "## Define AOI and query GEE for DEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f54f309-2c34-49f7-a99b-bd9225207ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----Manual AOI\n",
    "# save just the coordinates first for later use\n",
    "aoi_coords = [\n",
    "[-134.379943, 58.417939],\n",
    "[-134.362549, 58.388341],\n",
    "[-134.361008, 58.3727101],\n",
    "[-134.369808, 58.359844],\n",
    "[-134.470524, 58.3375671],\n",
    "[-134.558482, 58.381999],\n",
    "[-134.379943, 58.41793911]\n",
    "]\n",
    "# convert to ee.Geometry\n",
    "aoi = ee.Geometry.Polygon(aoi_coords)\n",
    "\n",
    "aoi_area = aoi.area().getInfo()\n",
    "print(f\"AOI = {int(aoi_area/1e6)} km2\")\n",
    "\n",
    "# -----Query GEE for DEM\n",
    "dem = utils.query_gee_for_dem(aoi)\n",
    "# Save the DEM to file\n",
    "dem_file = os.path.join(out_folder, \"ArcticDEM_clipped.tif\")\n",
    "if not os.path.exists(dem_file):\n",
    "    dem = dem.set('system:time_start', 0)\n",
    "    dem_xr = dem.wx.to_xarray(region=aoi, scale=10)\n",
    "    dem_xr.isel(time=0).rio.to_raster(dem_file)\n",
    "    print(\"Clipped DEM saved to file:\", dem_file)\n",
    "else:\n",
    "    print(\"Clipped DEM already exists in file, skipping.\")\n",
    "\n",
    "# -----Identify the best UTM zone for outputs\n",
    "def convert_wgs_to_utm(lon: float, lat: float):\n",
    "    utm_band = str(int((np.floor((lon + 180) / 6) % 60) + 1))\n",
    "    if len(utm_band) == 1:\n",
    "        utm_band = '0' + utm_band\n",
    "    if lat >= 0:\n",
    "        epsg_code = 'EPSG:326' + utm_band\n",
    "        return epsg_code\n",
    "    epsg_code = 'EPSG:327' + utm_band\n",
    "    return epsg_code\n",
    "\n",
    "aoi_cen_lon = float(np.nanmean(np.array(aoi_coords)[:,0]))\n",
    "aoi_cen_lat = float(np.nanmean(np.array(aoi_coords)[:,1]))\n",
    "utm_crs = convert_wgs_to_utm(aoi_cen_lon, aoi_cen_lat)\n",
    "print(\"Optimal UTM zone =\", utm_crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce05779-ea14-4d5c-af9b-6f16c353e9c0",
   "metadata": {},
   "source": [
    "## Query GEE for imagery, classify, save outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea710e1-bd38-4bd9-816c-b2259f77ba57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test with one dataset\n",
    "dataset = \"Sentinel-2_SR\"\n",
    "scale = 30\n",
    "\n",
    "# Make sure out_folder exists\n",
    "os.makedirs(out_folder, exist_ok=True)\n",
    "\n",
    "# Create a colormap for plotting classified images\n",
    "colors = [\"#4eb3d3\", \"#6a51a3\", \"#084081\", \"#fe9929\", \"#252525\"] \n",
    "bounds = [1, 2, 3, 4, 5, 6] \n",
    "cmap = matplotlib.colors.ListedColormap(colors)\n",
    "norm = matplotlib.colors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "# Create arrays of date start and date ends to iterate over\n",
    "date_start_arr = np.arange(np.datetime64(date_start), np.datetime64(date_end))\n",
    "date_end_arr = date_start_arr + np.timedelta64(1, 'D')\n",
    "\n",
    "for d_start, d_end in tqdm(list(zip(date_start_arr, date_end_arr))):\n",
    "    # Define outputs\n",
    "    image_file = os.path.join(out_folder, f\"{d_start}_{dataset}.tif\")\n",
    "    classified_image_file = os.path.join(out_folder, f\"{d_start}_{dataset}_classified.tif\")\n",
    "    figure_file = os.path.join(out_folder, f\"{d_start}_{dataset}_results.png\")\n",
    "\n",
    "    # Continue if outputs exist\n",
    "    if os.path.exists(image_file) & os.path.exists(classified_image_file) & os.path.exists(figure_file):\n",
    "        print(f\"Outputs already exist, skipping {d_start} to {d_end}\")\n",
    "        continue\n",
    "    \n",
    "    # Query GEE for images\n",
    "    image_col = utils.query_gee_for_imagery(\n",
    "        dataset = dataset,\n",
    "        aoi = aoi,\n",
    "        date_start = str(d_start), \n",
    "        date_end = str(d_end), \n",
    "        fill_portion = min_aoi_coverage, \n",
    "        mask_clouds = mask_clouds, \n",
    "        scale = None, \n",
    "        verbose = False\n",
    "    )\n",
    "\n",
    "    # Check that there were any results\n",
    "    if image_col.size().getInfo() < 1:\n",
    "        print(f\"No images found for {d_start} to {d_end}\")\n",
    "        continue\n",
    "\n",
    "    classified_image_col = utils.classify_image_collection(\n",
    "        collection = image_col,\n",
    "        dataset = dataset,\n",
    "        verbose = False\n",
    "    )\n",
    "\n",
    "    # Convert image \"collections\" to xarray.Datasets and save to file\n",
    "    image_xr = image_col.first().wx.to_xarray(region=aoi, scale=scale, crs=utm_crs).isel(time=0)\n",
    "    image_xr.rio.to_raster(image_file)\n",
    "    print(\"Image saved to:\", image_file)\n",
    "    \n",
    "    classified_image_xr = classified_image_col.first().wx.to_xarray(region=aoi, scale=scale, crs=utm_crs).isel(time=0)\n",
    "    classified_image_xr.rio.to_raster(classified_image_file)\n",
    "    print(\"Classified image saved to:\", classified_image_file)    \n",
    "\n",
    "    plt.rcParams.update({\"font.size\": 12, \"font.sans-serif\": \"Verdana\"})\n",
    "    fig, ax = plt.subplots(2, 1, figsize=(10,10))\n",
    "    fig.subplots_adjust(right=1.0)\n",
    "    cax = fig.add_axes([0.83, 0.14, 0.02, 0.3])\n",
    "    # RGB\n",
    "    if dataset==\"Landsat\":\n",
    "        rgb_bands = [\"SR_B4\", \"SR_B3\", \"SR_B2\"]\n",
    "    else:\n",
    "        rgb_bands = [\"B4\", \"B3\", \"B2\"]\n",
    "    ax[0].imshow(\n",
    "        np.dstack([image_xr[rgb_bands[0]], image_xr[rgb_bands[1]], image_xr[rgb_bands[2]]]),\n",
    "        extent=(\n",
    "            min(image_xr.x.data)/1e3, max(image_xr.x.data)/1e3, \n",
    "            min(image_xr.y.data)/1e3, max(image_xr.y.data)/1e3\n",
    "        )\n",
    "    )\n",
    "    # classified image\n",
    "    im = ax[1].imshow(\n",
    "        classified_image_xr.classification,\n",
    "        cmap=cmap,\n",
    "        norm=norm,\n",
    "        extent=(\n",
    "            min(classified_image_xr.x.data)/1e3, max(classified_image_xr.x.data)/1e3, \n",
    "            min(classified_image_xr.y.data)/1e3, max(classified_image_xr.y.data)/1e3\n",
    "        )\n",
    "    )\n",
    "    cbar = fig.colorbar(im, cax=cax)\n",
    "    cbar.set_ticks([1.5, 2.5, 3.5, 4.5, 5.5])\n",
    "    cbar.set_ticklabels([\n",
    "        'Snow', 'Shadowed snow', 'Ice', 'Rock/debris', 'Water'\n",
    "    ])\n",
    "    cbar.ax.minorticks_off()\n",
    "    ax[0].set_ylabel(\"Northing [km]\")\n",
    "    ax[1].set_ylabel(\"Northing [km]\")\n",
    "    ax[1].set_xlabel(\"Easting [km]\")\n",
    "    \n",
    "    # Save figure\n",
    "    fig.savefig(figure_file, dpi=300, bbox_inches='tight')\n",
    "    print(\"Figure saved to:\", figure_file)\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa8a3fa",
   "metadata": {},
   "source": [
    "## Calculate snow cover statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9018c4d",
   "metadata": {},
   "source": [
    "Let's see how the original statistics play out for this case. Here is a Python version that we can use for proof-of-concept. The original function for reference is located in `glasee_pipeline_utils.py > calculate_snow_cover_statistics`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d61ebb-9565-4a90-818b-311baf5f7c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_snow_cover_statistics_python(\n",
    "        classified_image_file: str = None, \n",
    "        dem_file: str = None, \n",
    "        scale: int = None,\n",
    "        ):\n",
    "    \"\"\"\n",
    "    Calculate snow cover statistics the input image. The function will calculate the following\n",
    "    statistics for each image: snow area, ice area, rock area, water area, glacier area, SLA,\n",
    "    SLA upper bound, and SLA lower bound. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    classified_image_file : str\n",
    "        File path to the classified image (e.g., from the classify_image_collection function).\n",
    "    dem_file : str\n",
    "        File path to the DEM (e.g., clipped ArcticDEM).\n",
    "    scale : int\n",
    "        Spatial scale in meters to use for area calculations and DEM sampling. If None, defaults to 30 m for Landsat and 10 m for Sentinel-2.\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    None\n",
    "    \"\"\"\n",
    "    # --- Check if output figure already exists ---\n",
    "    fig_file = classified_image_file.replace('_classified.tif', '_SLA.png')\n",
    "    if os.path.exists(fig_file):\n",
    "        return\n",
    "\n",
    "    # --- Load inputs ---\n",
    "    date = os.path.basename(classified_image_file).split(\"_\")[0]\n",
    "    dataset = os.path.basename(classified_image_file).split(\"_\")[1]\n",
    "    print(date, dataset)\n",
    "\n",
    "    if not scale:\n",
    "        scale = 30 if (dataset == 'Landsat') else 10\n",
    "\n",
    "    classified_image = rxr.open_rasterio(classified_image_file).squeeze()\n",
    "    classified_image = classified_image.where(classified_image != classified_image.attrs.get(\"_FillValue\"))\n",
    "    \n",
    "    dem = rxr.open_rasterio(dem_file).squeeze()\n",
    "    dem = dem.rio.reproject_match(classified_image)\n",
    "    dem = dem.where(dem != dem.attrs.get(\"_FillValue\"))\n",
    "\n",
    "    # --- Calculate areas for each class ---\n",
    "    pixel_area = float(scale) ** 2\n",
    "    aoi_area = float(np.count_nonzero(~np.isnan(dem.data))) * pixel_area\n",
    "\n",
    "    snow_mask = (classified_image == 1) | (classified_image == 2)\n",
    "    ice_mask = classified_image == 3\n",
    "    rock_mask = classified_image == 4\n",
    "    water_mask = classified_image == 5\n",
    "\n",
    "    snow_area = float(snow_mask.sum()) * pixel_area\n",
    "    ice_area = float(ice_mask.sum()) * pixel_area\n",
    "    rock_area = float(rock_mask.sum()) * pixel_area\n",
    "    water_area = float(water_mask.sum()) * pixel_area\n",
    "    glacier_area = snow_area + ice_area\n",
    "\n",
    "    # --- Estimate Snowline Altitude (SLA) ---\n",
    "    snow_dem = dem.where(snow_mask)\n",
    "    sla = float(snow_dem.quantile(0.05, skipna=True))\n",
    "\n",
    "    # --- Estimate SLA upper and lower bounds ---\n",
    "    # \"Reference system switch\": find the DEM percentile corresponding to the SLA\n",
    "    below_sla_mask = dem < sla\n",
    "    below_sla_mask_area = float(below_sla_mask.sum()) * pixel_area\n",
    "    sla_percentile_dem = (below_sla_mask_area / aoi_area) * 100\n",
    "\n",
    "    # Upper bound\n",
    "    snow_free_mask = (classified_image >= 3)\n",
    "    above_sla_mask = dem > sla\n",
    "    sla_upper_mask = snow_free_mask & above_sla_mask\n",
    "    sla_upper_mask_area = float(sla_upper_mask.sum()) * pixel_area\n",
    "    # DEM percentile to sample = (SLA percentile) + (Area snow-free above SLA / Total AOI Area)\n",
    "    sla_upper_percentile = sla_percentile_dem + (sla_upper_mask_area / aoi_area) * 100\n",
    "    sla_upper = float(dem.quantile(sla_upper_percentile / 100, skipna=True))\n",
    "\n",
    "    # Lower bound\n",
    "    sla_lower_mask = snow_mask & below_sla_mask\n",
    "    sla_lower_mask_area = float(sla_lower_mask.sum()) * pixel_area\n",
    "    # DEM percentile to sample = (SLA percentile) - (Area snow-covered below SLA / Total AOI Area)\n",
    "    sla_lower_percentile = sla_percentile_dem - (sla_lower_mask_area / aoi_area) * 100\n",
    "    sla_lower = float(dem.quantile(sla_lower_percentile / 100, skipna=True))\n",
    "\n",
    "    # --- Plot results ---\n",
    "    plt.rcParams.update({\"font.size\": 12, \"font.sans-serif\": \"Verdana\"})\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12,6), gridspec_kw=dict(width_ratios=[1, 1.5]))\n",
    "    \n",
    "    # Classified image + SLA contours\n",
    "    colors = [\"#4eb3d3\", \"#6a51a3\", \"#084081\", \"#fe9929\", \"#252525\"] \n",
    "    bounds = [1, 2, 3, 4, 5, 6] \n",
    "    cmap = matplotlib.colors.ListedColormap(colors)\n",
    "    norm = matplotlib.colors.BoundaryNorm(bounds, cmap.N)\n",
    "    im = ax[0].imshow(\n",
    "        classified_image,\n",
    "        cmap=cmap,\n",
    "        norm=norm,\n",
    "        extent=(\n",
    "            min(classified_image.x.data)/1e3, max(classified_image.x.data)/1e3, \n",
    "            min(classified_image.y.data)/1e3, max(classified_image.y.data)/1e3\n",
    "        )\n",
    "    )\n",
    "    cbar = fig.colorbar(im, ax=ax[0], orientation='horizontal', shrink=0.8)\n",
    "    cbar.set_ticks([1.5, 2.5, 3.5, 4.5, 5.5])\n",
    "    cbar.set_ticklabels([\n",
    "        'Snow', 'Shadowed\\nsnow', 'Ice', 'Rock/debris', 'Water'\n",
    "    ], fontsize=8)\n",
    "    cbar.ax.minorticks_off()\n",
    "    ax[0].set_ylabel(\"Northing [km]\")\n",
    "    ax[0].set_xlabel(\"Easting [km]\")\n",
    "\n",
    "    X,Y = np.meshgrid(dem.x.data, dem.y.data)\n",
    "    ax[0].contour(np.divide(X, 1e3), np.divide(Y, 1e3), dem.data, levels=[sla], colors='k', linestyles='solid')\n",
    "    ax[0].contour(np.divide(X, 1e3), np.divide(Y, 1e3), dem.data, levels=[sla_upper], colors='k', linestyles='dashed')\n",
    "    ax[0].contour(np.divide(X, 1e3), np.divide(Y, 1e3), dem.data, levels=[sla_lower], colors='k', linestyles='dotted')\n",
    "\n",
    "    # Histograms of all elevations and snow elevations with lines for SLA metrics\n",
    "    bins = np.linspace(np.nanmin(dem.data), np.nanmax(dem.data), num=100)\n",
    "    ax[1].hist(dem.data.ravel(), bins=bins, color='gray', alpha=1, label=\"All elevations\")\n",
    "    ax[1].hist(snow_dem.data.ravel(), bins=bins, color=colors[0], alpha=1, label=\"Snow elevations\")\n",
    "    ax[1].axvline(sla_upper, color='k', linestyle='dashed', label=\"SLA$_{upper}$ = \"+str(int(sla_upper))+\" m\")\n",
    "    ax[1].axvline(sla, color='k', linestyle='solid', label=\"SLA = \"+str(int(sla))+\" m\")\n",
    "    ax[1].axvline(sla_lower, color='k', linestyle='dotted', label=\"SLA$_{lower}$ = \"+str(int(sla_lower))+\" m\")\n",
    "    ax[1].legend(loc='upper right')\n",
    "    ax[1].set_xlabel(\"Elevation [m]\")\n",
    "    ax[1].set_ylabel(\"Counts\")\n",
    "\n",
    "    fig.suptitle(f\"{date} {dataset}\")\n",
    "\n",
    "    # Save to file\n",
    "    fig.savefig(fig_file, dpi=300, bbox_inches='tight')\n",
    "    print(\"Figure saved to:\", fig_file)\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "    return\n",
    "\n",
    "# Iterate over the classified images\n",
    "classified_image_files = sorted(glob(os.path.join(out_folder, \"*_classified.tif\")))\n",
    "print(f\"Located {len(classified_image_files)} classified image files.\")\n",
    "\n",
    "for file in tqdm(classified_image_files):\n",
    "    calculate_snow_cover_statistics_python(\n",
    "        file,\n",
    "        dem_file,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3d2813",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
